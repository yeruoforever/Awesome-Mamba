# Awesome-Mamba
Awsome works based on SSM and Mamba

## SSMs

### Blog

* [A Visual Guide to Mamba and State Space Models (MAARTEN GROOTENDORST)](https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state)
* [Introduction to State Space Models (SSM) (lbourdois Lo√Øck BOURDOIS)](https://huggingface.co/blog/lbourdois/get-on-the-ssm-train)

### Post

* [H3: Language Modeling with State Space Models and (Almost) No Attention](https://hazyresearch.stanford.edu/blog/2023-01-20-h3)
* [The Annotated S4](https://srush.github.io/annotated-s4/)
* [Structured State Spaces for Sequence Modeling (S4) part 1](https://hazyresearch.stanford.edu/blog/2022-01-14-s4-1)
* [Structured State Spaces for Sequence Modeling (S4) part 2](https://hazyresearch.stanford.edu/blog/2022-01-14-s4-2)
* [Structured State Spaces for Sequence Modeling (S4) part 3](https://hazyresearch.stanford.edu/blog/2022-01-14-s4-3)
* [HiPPO: Recurrent Memory with Optimal Polynomial Projections](https://hazyresearch.stanford.edu/blog/2020-12-05-hippo)

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[The pitfalls of next-token prediction](https://arxiv.org/pdf/2403.06963)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.06963)|
|[The Hidden Attention of Mamba Models](https://arxiv.org/abs/2403.01590)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.01590)|
|[Theoretical Foundations of Deep Selective State-Space Models](https://arxiv.org/abs/2402.19047)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.19047)|
|[Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10211)|
|[Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data](https://arxiv.org/abs/2402.05892)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.05892)|
|[Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks](https://arxiv.org/abs/2402.04248)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.04248)|
|[Is Mamba Capable of In-Context Learning?](https://arxiv.org/abs/2402.03170)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.03170)|
|[BlackMamba: Mixture of Experts for State-Space Models](https://arxiv.org/abs/2402.01771)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.01771)|
|[Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)|2023|arXiv| code |[pdf](https://arxiv.org/abs/2312.00752)|
|[Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors](https://arxiv.org/abs/2310.02980)|2023|arXiv| code |[pdf](https://arxiv.org/abs/2310.02980)|
|[What Makes Convolutional Models Great on Long Sequence Modeling?](https://arxiv.org/abs/2210.09298)|2023|ICLR 2023| code |[pdf](https://arxiv.org/abs/2210.09298)|
|[Mega: Moving Average Equipped Gated Attention](https://arxiv.org/abs/2209.10655)|2023|ICLR 2023| code |[pdf](https://arxiv.org/abs/2209.10655)|
|[Liquid Structural State-Space Models](https://arxiv.org/abs/2209.12951)|2023|ICLR 2023| code |[pdf](https://arxiv.org/abs/2209.12951)|
|[Hungry Hungry Hippos: Towards Language Modeling with State Space Models](https://arxiv.org/abs/2212.14052)|2022|ICLR 2023| code |[pdf](https://arxiv.org/abs/2212.14052)|
|[On the Parameterization and Initialization of Diagonal State Space Models](https://arxiv.org/abs/2206.11893)|2022|NeurIPS 2022| code |[pdf](https://arxiv.org/abs/2206.11893)|
|[S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces](https://arxiv.org/abs/2210.06583)|2022|NeurIPS 2022| [code](https://github.com/state-spaces/s4/tree/main/models/s4nd) |[pdf](https://arxiv.org/abs/2210.06583)|
|[Long Range Language Modeling via Gated State Spaces](https://arxiv.org/abs/2206.13947)|2022|ICLR 2023| code |[pdf](https://arxiv.org/abs/2206.13947)|
|[Simplified State Space Layers for Sequence Modeling](https://arxiv.org/abs/2208.04933)|2022|ICLR 2023| [code](https://github.com/lindermanlab/S5) |[pdf](https://arxiv.org/abs/2208.04933)|
|[How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections](https://arxiv.org/abs/2206.12037)|2022|ICLR 2023| code |[pdf](https://arxiv.org/abs/2206.12037)|
|[Diagonal State Spaces are as Effective as Structured State Spaces](https://arxiv.org/abs/2203.14343)|2022|NeurIPS 2022 - Spotlight| code |[pdf](https://arxiv.org/abs/2203.14343)|
|[Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396)|2021|ICLR 2022 - Outstanding Paper HM| [code](https://github.com/state-spaces/s4/tree/main/models/s4) |[pdf](https://arxiv.org/abs/2111.00396)|
|[Combining Recurrent, Convolutional, and Continuous-time Models with the Linear State Space Layer](https://arxiv.org/abs/2110.13985)|2021|NeurIPS 2021| code |[pdf](https://arxiv.org/abs/2110.13985)|
|[HiPPO: Recurrent Memory with Optimal Polynomial Projections](https://arxiv.org/abs/2008.07669)|2020|NeurIPS 2020 - Spotlight| [code](https://github.com/state-spaces/s4/tree/main/models/hippo) |[pdf](https://arxiv.org/abs/2008.07669)|



## Time Series

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting](https://arxiv.org/abs/2403.09898)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09898)|
|[Is Mamba Effective for Time Series Forecasting?](https://arxiv.org/abs/2403.11144)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.11144)|


### Audio generation

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Multichannel Long-Term Streaming Neural Speech Enhancement for Static and Moving Speakers](https://arxiv.org/abs/2403.07675)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.07675)|
|[MambaLithium: Selective state space model for remaining-useful-life, state-of-health, and state-of-charge estimation of lithium-ion batteries](https://arxiv.org/abs/2403.05430)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.05430)|
|[MambaStock: Selective state space model for stock prediction](https://arxiv.org/abs/2402.18959)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.18959)|
|[It's Raw! Audio Generation with State-Space Models](https://arxiv.org/abs/2202.09729)|2022|ICML 2022 - Long Talk| [code](https://github.com/state-spaces/s4/tree/main/models/sashimi) |[pdf](https://arxiv.org/abs/2202.09729)|

##  NLP

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes](https://arxiv.org/abs/2403.05795)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.05795)|
|[DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models](https://arxiv.org/abs/2403.00818)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.00818)|
|[MambaByte: Token-free Selective State Space Model](https://arxiv.org/abs/2401.13660)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13660)|
|[MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.04081)|



## Graph Neural Network

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Graph Mamba: Towards Learning on Graphs with State Space Models](https://arxiv.org/abs/2402.08678)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.08678)|


## Computer Vision

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[LocalMamba: Visual State Space Model with Windowed Selective Scan](https://arxiv.org/abs/2403.09338)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09338)|
|[Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding](https://arxiv.org/abs/2403.09626)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09626)|
|[EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](https://arxiv.org/abs/2403.09977)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09977)|
|[On the low-shot transferability of [V]-Mamba](https://arxiv.org/abs/2403.10696)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.10696)|
|[VideoMamba: State Space Model for Efficient Video Understanding](https://arxiv.org/abs/2403.06977)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.06977)|
|[MamMIL: Multiple Instance Learning for Whole Slide Images with State Space Models](https://arxiv.org/abs/2403.05160)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.05160)|
|[MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection](https://arxiv.org/abs/2403.02148)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.02148)|
|[MambaIR: A Simple Baseline for Image Restoration with State-Space Model](https://arxiv.org/abs/2402.15648)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.15648)|
|[Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning](https://arxiv.org/abs/2402.15761)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.15761)|
|[Pan-Mamba: Effective pan-sharpening with State Space Model](https://arxiv.org/abs/2402.12192.pdf)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.12192.pdf)|
|[U-shaped Vision Mamba for Single Image Dehazing](https://arxiv.org/abs/2402.04139)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.04139)|
|[Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/abs/2401.09417)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2401.09417)|


### Super-Resolution

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Activating Wider Areas in Image Super-Resolution](https://arxiv.org/abs/2403.08330)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.08330)|

### Digital human

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaTalk: Efficient Holistic Gesture Synthesis with Selective State Space Models](https://arxiv.org/abs/2403.09471)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09471)|

### Human Pose Estimation

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Motion Mamba: Efficient and Long Sequence Motion Generation with Hierarchical and Bidirectional Selective SSM](https://arxiv.org/abs/2403.07487)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.07487)|

### Foundation Model

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining](https://arxiv.org/abs/2402.03302)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.03302)|



### Medical Image Analysis

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MD-Dose: A diffusion model based on the Mamba for radiation dose prediction](https://arxiv.org/abs/2403.08479.pdf)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.08479.pdf)|


#### Muliti-Modal Medical Image Analysis

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|

#### Medical Image Segmentation

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Large Window-based Mamba UNet for Medical Image Segmentation: Beyond Convolution and Self-attention](https://arxiv.org/abs/2403.07332)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.07332)|
|[VM-UNET-V2 Rethinking Vision Mamba UNet for Medical Image Segmentation](https://arxiv.org/abs/2403.09157)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.09157)|
|[LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation](https://arxiv.org/abs/2403.05246)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.05246)|
|[Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation](https://arxiv.org/abs/2402.10887)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10887)|
|[P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation](https://arxiv.org/pdf/2402.08506)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.08506)|
|[Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2402.07245)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.07245)|
|[Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation](https://arxiv.org/abs/2402.05079)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.05079)|
|[VM-UNet: Vision Mamba UNet for Medical Image Segmentation](https://arxiv.org/abs/2402.02491)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.02491)|
|[Vivim: a Video Vision Mamba for Medical Video Object Segmentation](https://arxiv.org/abs/2401.14168)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.14168)|
|[SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation](https://arxiv.org/abs/2401.13560)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13560)|
|[U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation](https://arxiv.org/abs/2401.04722)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.04722)|



#### Medical Image Calssification

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaMIL: Enhancing Long Sequence Modeling with Sequence Reordering in Computational Pathology](https://arxiv.org/abs/2403.06800)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.06800)|
|[MedMamba: Vision Mamba for Medical Image Classification](https://arxiv.org/abs/2403.03849)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.03849)|






#### Medical Image Registration

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration](https://arxiv.org/abs/2401.13934)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13934)|


#### Others

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Motion-Guided Dual-Camera Tracker for Low-Cost Skill Evaluation of Gastric Endoscopy](https://arxiv.org/abs/2403.05146)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.05146)|
|[FD-Vision Mamba for Endoscopic Exposure Correction](https://arxiv.org/abs/2402.06378)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.06378)|
|[Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models](https://arxiv.org/abs/2403.03900)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.03900)|
|[Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling](https://arxiv.org/abs/2403.03234)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.03234)|


### Point Cloud

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Point Could Mamba: Point Cloud Learning via State Space Model](https://arxiv.org/abs/2403.00762)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2403.00762)|
|[PointMamba: A Simple State Space Model for Point Cloud Analysis](https://arxiv.org/abs/2402.10739)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10739)|


## Structulal Data

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[A multi-cohort study on prediction of acute brain dysfunction states using selective state space models](https://arxiv.org/abs/2403.07201)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2403.07201)|
|[MambaTab: A Simple Yet Effective Approach for Handling Tabular Data](https://arxiv.org/abs/2401.08867)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.08867)|

## Competitor

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](https://arxiv.org/abs/2402.19427)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.19427)|
|[Gated Linear Attention Transformers with Hardware-Efficient Training](https://arxiv.org/abs/2312.06635)|2023|arXiv| code |[pdf](https://arxiv.org/abs/2312.06635)|

