# Awesome-Mamba
Awsome works based on SSM and Mamba

## SSMs

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10211)|
|[Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data](https://arxiv.org/abs/2402.05892)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.05892)|
|[Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks](https://arxiv.org/abs/2402.04248)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.04248)|
|[Is Mamba Capable of In-Context Learning?](https://arxiv.org/abs/2402.03170)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.03170)|
|[BlackMamba: Mixture of Experts for State-Space Models](https://arxiv.org/abs/2402.01771)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.01771)|
|[Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)|2023|arXiv| code |[pdf](https://arxiv.org/abs/2312.00752)|
|[Hungry Hungry Hippos: Towards Language Modeling with State Space Models](https://arxiv.org/abs/2212.14052)|2022|ICLR 2023| code |[pdf](https://arxiv.org/abs/2212.14052)|
|[On the Parameterization and Initialization of Diagonal State Space Models](https://arxiv.org/abs/2206.11893)|2022|arXiv| code |[pdf](https://arxiv.org/abs/2206.11893)|
|[S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces](https://arxiv.org/abs/2210.06583)|2022|arXiv| code |[pdf](https://arxiv.org/abs/2210.06583)|
|[How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections](https://arxiv.org/abs/2206.12037)|2022|arXiv| code |[pdf](https://arxiv.org/abs/2206.12037)|
|[Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396)|2021|arXiv| code |[pdf](https://arxiv.org/abs/2111.00396)|
|[HiPPO: Recurrent Memory with Optimal Polynomial Projections](https://arxiv.org/abs/2008.07669)|2020|arXiv| code |[pdf](https://arxiv.org/abs/2008.07669)|


## Time Series

##  NLP

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaByte: Token-free Selective State Space Model](https://arxiv.org/abs/2401.13660)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13660)|
|[MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.04081)|



## Graph Neural Network

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Graph Mamba: Towards Learning on Graphs with State Space Models](https://arxiv.org/abs/2402.08678)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.08678)|


## Computer Vision

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Pan-Mamba: Effective pan-sharpening with State Space Model](https://arxiv.org/pdf/2402.12192.pdf)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.12192.pdf)|
|[U-shaped Vision Mamba for Single Image Dehazing](https://arxiv.org/abs/2402.04139)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.04139)|
|[Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/abs/2401.09417)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.09417)|


### Foundation Model

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining](https://arxiv.org/abs/2402.03302)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.03302)|



### Medical Image Analysis

#### Medical Image Segmentation

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation](https://arxiv.org/abs/2402.10887)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10887)|
|[P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation](https://arxiv.org/pdf/2402.08506)|2024|arXiv| code |[pdf](https://arxiv.org/pdf/2402.08506)|
|[Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2402.07245)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.07245)|
|[Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation](https://arxiv.org/abs/2402.05079)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.05079)|
|[VM-UNet: Vision Mamba UNet for Medical Image Segmentation](https://arxiv.org/abs/2402.02491)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.02491)|
|[Vivim: a Video Vision Mamba for Medical Video Object Segmentation](https://arxiv.org/abs/2401.14168)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.14168)|
|[SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation](https://arxiv.org/abs/2401.13560)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13560)|
|[U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation](https://arxiv.org/abs/2401.04722)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.04722)|









#### Medical Image Registration

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration](https://arxiv.org/abs/2401.13934)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.13934)|


#### Others

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[FD-Vision Mamba for Endoscopic Exposure Correction](https://arxiv.org/abs/2402.06378)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.06378)|

### Point Cloud

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[PointMamba: A Simple State Space Model for Point Cloud Analysis](https://arxiv.org/abs/2402.10739)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2402.10739)|


## Structulal Data

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[MambaTab: A Simple Yet Effective Approach for Handling Tabular Data](https://arxiv.org/abs/2401.08867)|2024|arXiv| code |[pdf](https://arxiv.org/abs/2401.08867)|

## Competitor

|Title|Year|Venue|Code|PDF|
|---|---|---|---|---|
|[Gated Linear Attention Transformers with Hardware-Efficient Training](https://arxiv.org/abs/2312.06635)|2023|arXiv| code |[pdf](https://arxiv.org/abs/2312.06635)|

